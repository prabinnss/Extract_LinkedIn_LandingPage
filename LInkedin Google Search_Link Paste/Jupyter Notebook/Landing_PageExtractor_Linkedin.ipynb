{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00597488",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import itertools\n",
    "import time\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.worksheet.hyperlink import Hyperlink\n",
    "from selenium.webdriver.chrome.options import Options  \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca67d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinkedIn_Search(person_name):\n",
    "\n",
    "    # Use Chrome options to disable bot detection\n",
    "    chrome_options = Options()\n",
    "    \n",
    "    # Add a User-Agent string to mimic a real browser\n",
    "    user_agent = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36\"\n",
    "    chrome_options.add_argument(f\"user-agent={user_agent}\")\n",
    "    \n",
    "    # Disable automation flags for Chrome\n",
    "    #chrome_options.add_argument(\"headless\")\n",
    "    chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "    \n",
    "    # Randomize window size\n",
    "    window_width = random.randint(1024, 1920)\n",
    "    window_height = random.randint(768, 1080)\n",
    "    chrome_options.add_argument(f\"--window-size={window_width},{window_height}\")\n",
    "    \n",
    "    \n",
    "    service=Service(r\"C:\\Users\\paudelp2\\Documents\\Python Scripts\\Extract_LinkedIn_LandingPage-main\\Jupyter Notebook\\chromedriver.exe\")\n",
    "     # Initialize the Chrome driver with headless mode\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options) \n",
    "\n",
    "    \n",
    "    google_url = 'https://www.google.com/'\n",
    "    driver.get(google_url)\n",
    "    time.sleep(random.uniform(5,7))\n",
    "    WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.NAME, 'q')))\n",
    "    search_query = f'\"{person_name}\" \"VBOA\"'\n",
    "    search_box = driver.find_element(By.NAME, 'q')\n",
    "    search_box.send_keys(search_query)\n",
    "    \n",
    "    # Simulate slight delay before submitting to mimic human typing\n",
    "    time.sleep(random.uniform(2, 4))\n",
    "    \n",
    "    search_box.submit()\n",
    "    time.sleep(random.uniform(5,7))\n",
    "    try:\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//a[contains(@href, \"linkedin.com/in/\")]')))\n",
    "        linkedin_link = driver.find_element(By.XPATH, '//a[contains(@href, \"linkedin.com/in/\")]').get_attribute('href')\n",
    "        landing_page=(linkedin_link)\n",
    "        return landing_page\n",
    "    except Exception as e:\n",
    "        print(\"LinkedIn profile not found or search results took too long to load.\")\n",
    "        linkedin_link = None\n",
    "        return None\n",
    "\n",
    "        # Closing the browser\n",
    "    print(landing_page)\n",
    "    driver.quit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7448fbb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "excel_file_path=''\n",
    "def update_excel_with_linkedin_links(excel_file):\n",
    "    # Load Excel file\n",
    "    pd_xl_file = pd.ExcelFile(excel_file_path)\n",
    "    \n",
    "    # Assuming the sheet is named 'Sheet1' (you can adjust this if necessary)\n",
    "    df = pd_xl_file.parse('Sheet1')\n",
    "    \n",
    "    # Assuming 'Person Name' is in the first column (index 0)\n",
    "    person_names = df.iloc[:, 0]\n",
    "    \n",
    "    # Create an empty list to hold LinkedIn URLs\n",
    "    linkedin_urls = []\n",
    "    \n",
    "    # Loop over each person and get their LinkedIn profile\n",
    "    for person_name in person_names:\n",
    "        print(f'Searching for LinkedIn profile of {person_name}')\n",
    "        linkedin_url = LinkedIn_Search(person_name)\n",
    "        if linkedin_url:\n",
    "            print(f'Found LinkedIn URL: {linkedin_url}')\n",
    "        else:\n",
    "            print(f'No LinkedIn URL found for {person_name}')\n",
    "        linkedin_urls.append(linkedin_url)\n",
    "    \n",
    "        # Load the existing workbook and the specific sheet you want to update\n",
    "        workbook = load_workbook(excel_file_path)\n",
    "        sheet = workbook.active\n",
    "\n",
    "        # Assuming LinkedIn URLs should be written in column 2 (B)\n",
    "        for row_num, linkedin_url in enumerate(linkedin_urls, start=2):  # Assuming the first row is header\n",
    "            sheet.cell(row=row_num, column=2).hyperlink=linkedin_url\n",
    "\n",
    "        # Save the updated Excel file\n",
    "        workbook.save(excel_file_path)\n",
    "        print('Excel file updated with LinkedIn URLs.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327cc081",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# File path to the Excel file\n",
    "excel_file_path = r\"C:\\Users\\paudelp2\\Documents\\Python Scripts\\Extract_LinkedIn_LandingPage-main\\Excel Files\\CPA List.xlsx\"\n",
    "\n",
    "# update the Excel file\n",
    "update_excel_with_linkedin_links(excel_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2624eea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a97831a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df41a33-e2b9-4649-8fc9-95c5192e8ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63eedce-227a-4248-b90d-1e540796bfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "excel_file_path = r\"C:\\Users\\paudelp2\\Documents\\Python Scripts\\Extract_LinkedIn_LandingPage-main\\Excel Files\\CPA List.xlsx\"\n",
    "\n",
    "def Linkedin_opener_VBOA_Searcher(excel_file):\n",
    "    # Load Excel file\n",
    "    pd_xl_file = pd.ExcelFile(excel_file_path)\n",
    "    \n",
    "    # Assuming the sheet is named 'Sheet1'\n",
    "    df = pd_xl_file.parse('Sheet1')\n",
    "    \n",
    "    # Assuming 'Linked Url' is in the second column (index 1)\n",
    "    extracted_linkedin_urls = df.iloc[:, 1]\n",
    "    \n",
    "    # Create empty lists to hold LinkedIn URLs and VBOA results\n",
    "    linkedin_urls = []\n",
    "    vboa_results = []\n",
    "    \n",
    "    # Loop over each extracted LinkedIn URL\n",
    "    for extracted_linkedin_url in extracted_linkedin_urls:\n",
    "        linkedin_url = extracted_linkedin_url\n",
    "\n",
    "          # Use Chrome options to disable bot detection\n",
    "        chrome_options = Options()\n",
    "    \n",
    "        # Add a User-Agent string to mimic a real browser\n",
    "        user_agent = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36\"\n",
    "        chrome_options.add_argument(f\"user-agent={user_agent}\")\n",
    "    \n",
    "        # Disable automation flags for Chrome\n",
    "        chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "        chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "    \n",
    "        # Randomize window size\n",
    "        window_width = random.randint(1024, 1920)\n",
    "        window_height = random.randint(768, 1080)\n",
    "        chrome_options.add_argument(f\"--window-size={window_width},{window_height}\")\n",
    "\n",
    "        \n",
    "        # Path to ChromeDriver\n",
    "        service = Service(r\"C:\\Users\\paudelp2\\Documents\\Python Scripts\\Extract_LinkedIn_LandingPage-main\\Jupyter Notebook\\chromedriver.exe\")\n",
    "   \n",
    "        chrome_options.add_argument(r\"user-data-dir=C:\\Users\\paudelp2\\AppData\\Local\\Google\\Chrome\\User Data\")\n",
    "        chrome_options.add_argument(r\"--profile-directory=Default\")\n",
    "        \n",
    "        # Initialize ChromeDriver with options\n",
    "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "        \n",
    "        try:\n",
    "            driver.get(linkedin_url)\n",
    "            time.sleep(random.uniform(5, 7))\n",
    "        \n",
    "            # Simulate scrolling down the page to load content\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(random.uniform(3, 5))\n",
    "        \n",
    "            # Check if \"VBOA\" exists on the page content\n",
    "            if \"VBOA\" in driver.page_source:\n",
    "                print(\"Yes\")\n",
    "                vboa_results.append(\"Yes\")  # Add \"Yes\" to results\n",
    "            else:\n",
    "                print(\"No\")\n",
    "                vboa_results.append(\"No\")  # Add \"No\" to results\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error accessing LinkedIn page: {linkedin_url} - {e}\")\n",
    "            vboa_results.append(\"Error\")  # Optional: add error handling\n",
    "        \n",
    "        linkedin_urls.append(linkedin_url)\n",
    "        driver.quit()\n",
    "    \n",
    "        # Load the existing workbook and the specific sheet you want to update\n",
    "        workbook = load_workbook(excel_file_path)\n",
    "        sheet = workbook.active\n",
    "    \n",
    "        # Write LinkedIn URLs and VBOA results to the sheet\n",
    "        for row_num, (linkedin_url, vboa_result) in enumerate(zip(linkedin_urls, vboa_results), start=2):  # Assuming the first row is header\n",
    "            sheet.cell(row=row_num, column=2).value = linkedin_url  # Write LinkedIn URL in column B\n",
    "            sheet.cell(row=row_num, column=3).value = vboa_result    # Write VBOA result in column C\n",
    "    \n",
    "        # Save the updated Excel file\n",
    "        workbook.save(excel_file_path)\n",
    "        print('Excel file updated with VBOA results.')\n",
    "\n",
    "# Call the function with the path to your Excel file\n",
    "Linkedin_opener_VBOA_Searcher(excel_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e11f7d2-ea84-4723-870b-8ab61e10426f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
