{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import itertools\n",
    "import time\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'webdriver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-12666189ad63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdriver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/Prabin/Repository/LinkdIn Scrapping/Jupyter Notebook/chromedriver'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'https://www.sharesansar.com/company/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompany_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'webdriver' is not defined"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome('/Users/Prabin/Repository/LinkdIn Scrapping/Jupyter Notebook/chromedriver')\n",
    "url='https://www.sharesansar.com/company/'+str(company_name.lower())\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def Price_History_Extract(company_name,stop_seconds):\n",
    "    #Parameters: company_name: company name short form\n",
    "    #           stop_seconds: time.sleep in each iteration in seconds. Increase if any error \n",
    "    #Returns: pricehistory_df as pandas dataframe\n",
    "    \n",
    "    \n",
    "    driver=webdriver.Chrome('/Users/Prabin/Repository/WebScrapping/Jupyter Notebook/chromedriver')\n",
    "    url='https://www.sharesansar.com/company/'+str(company_name.lower())\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Giving loading time to site\n",
    "    time.sleep(2)\n",
    "    WebDriverWait(driver, 60).until(EC.element_to_be_clickable((By.XPATH,'//*[@id=\"btn_cpricehistory\"]'))).click()\n",
    "    WebDriverWait(driver, 60).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"myTableCPriceHistory\"]/tbody/tr')))\n",
    "    driver.find_element_by_xpath('//*[@id=\"myTableCPriceHistory_length\"]/label/select/option[3]').click()\n",
    "    WebDriverWait(driver, 60).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"myTableCPriceHistory\"]/tbody/tr')))\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # finding no of pages:\n",
    "    for i in range(10,0,-1):\n",
    "        try:\n",
    "            pages_number=driver.find_element_by_xpath('//*[@id=\"myTableCPriceHistory_paginate\"]/span/a['+str(i)+']').text\n",
    "        except Exception:\n",
    "            continue\n",
    "        else:\n",
    "            print('Number of pages to extract: '+str(pages_number))\n",
    "            break\n",
    "            \n",
    "    \n",
    "\n",
    "    \n",
    "    # For extracting Headings:\n",
    "    print('Extracting Heading: ')\n",
    "    columns=len(driver.find_elements_by_xpath('//*[@id=\"myTableCPriceHistory\"]/tbody/tr[1]/td'))\n",
    "    pricehistory_heading=np.empty((1,columns),dtype=object)\n",
    "   \n",
    "    for h in range (1,columns+1):\n",
    "        pricehistory_heading[0,h-1]=driver.find_element_by_xpath\\\n",
    "        ('//*[@id=\"myTableCPriceHistory\"]/thead/tr/th['+str(h)+']').text\n",
    "    print(\"Successfully Extracted\")\n",
    "    pricehistory=pricehistory_heading\n",
    "\n",
    "\n",
    "    #For asset checking:\n",
    "    no_of_total_rows=1 # heading   \n",
    "\n",
    "    for i in range(1,min(int(pages_number)+1,31)):\n",
    "        print(\"\")\n",
    "        print(\"Currently Extracting in Page:\"+str(i))\n",
    "\n",
    "        # determining rows and columns of each page & creating numpy array of such rows and columns\n",
    "        rows=len(driver.find_elements_by_xpath('//*[@id=\"myTableCPriceHistory\"]/tbody/tr'))\n",
    "        columns=len(driver.find_elements_by_xpath('//*[@id=\"myTableCPriceHistory\"]/tbody/tr[1]/td'))\n",
    "        value=np.empty((rows,columns),dtype=object)\n",
    "        print('Rows in current page: '+str(rows))\n",
    "        print('Columns in current page: '+str(columns))\n",
    "        print(\"\")\n",
    "        #copyting each rows and colums of each page to array:value\n",
    "        for r in range(1,rows+1):\n",
    "            for c in range(1,columns+1):\n",
    "                value[r-1,c-1]=driver.find_element_by_xpath('//*[@id=\"myTableCPriceHistory\"]/tbody/tr['+str(r)+']/td['+str(c)+']').text\n",
    "        print(\"Successfully Extracted\")\n",
    "        pricehistory=np.concatenate((pricehistory,value))\n",
    "        #For assert checking\n",
    "        no_of_total_rows=no_of_total_rows+rows\n",
    "        no_of_columns=columns\n",
    "        \n",
    "        #clicking next page \n",
    "        if i!=(min(int(pages_number)+1,31)-1):\n",
    "            WebDriverWait(driver,60).until(EC.element_to_be_clickable((By.XPATH,'//*[@id=\"myTableCPriceHistory_next\"]'))).click()\n",
    "            time.sleep(stop_seconds)  # stops everything for seconds\n",
    "\n",
    "\n",
    "    assert pricehistory.shape[1]==no_of_columns\n",
    "    assert pricehistory.shape[0]==no_of_total_rows\n",
    "\n",
    "    #Changing array to pandas dataframe\n",
    "    pricehistory_df=pd.DataFrame(pricehistory)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Shape of Merged PriceHistory Data\",pricehistory.shape)\n",
    "    print(\"\") \n",
    "    print(\"Merged PriceHistory Data\")\n",
    "    #print(pricehistory_df)\n",
    "\n",
    "\n",
    "    driver.quit()\n",
    "    \n",
    "    return pricehistory_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SharePrice_History_Dataframe_to_CSV(Price_History,company_name,Sector):\n",
    "#      Sectors=['Commercial Banks',\n",
    "#            'Development Banks',\n",
    "#             'Finance',\n",
    "#             'Hotels And Tourism',\n",
    "#             'Hydro Power',\n",
    "#             'Investment',\n",
    "#             'Life Insurance',\n",
    "#             'Manufacturing And Processing',\n",
    "#             'Microfinance',\n",
    "#             'Non Life Insurance',\n",
    "#             'Others',\n",
    "#             'Tradings']\n",
    "    #Price_History:pandas dataframe to save to csv\n",
    "    #company:company name\n",
    "    #this function saves data to specific location provided below\n",
    "    Price_History.to_csv(r'/Users/Prabin/Repository/WebScrapping/CSV Fie/Share Price History/'+str(Sector)+'/SharePrice '+str(company_name.upper())+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To extract data of one sector\n",
    "def All_company_of_sector_extractor(Sector,stop_seconds):\n",
    "#Sectors=['Commercial Banks',\n",
    "#            'Development Banks',\n",
    "#             'Finance',\n",
    "#             'Hotels And Tourism',\n",
    "#             'Hydro Power',\n",
    "#             'Investment',\n",
    "#             'Life Insurance',\n",
    "#             'Manufacturing And Processing',\n",
    "#             'Microfinance',\n",
    "#             'Non Life Insurance',\n",
    "#             'Others',\n",
    "#             'Tradings']\n",
    "#\n",
    "#stop_seconds:time to stop in seconds\n",
    "#Saves all company of a sector as csv\n",
    "\n",
    "    pd_xl_file = pd.ExcelFile(\"/Users/Prabin/Repository/WebScrapping/Excel Files/Company Info.xlsm\")\n",
    "    df = pd_xl_file.parse(Sector)\n",
    "    Company_Symbol=df['SymbolÂ ']\n",
    "    print('No of Company under'+str(Sector)+'Category: '+str(Company_Symbol.shape[0]))\n",
    "    for Company in Company_Symbol:\n",
    "        print('Now Extracting data of: '+str(Company))\n",
    "        Price_History=Price_History_Extract(Company,stop_seconds)\n",
    "        SharePrice_History_Dataframe_to_CSV(Price_History,Company,Sector)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nSector='Development Banks'\\ncompany_name='men'\\nstop_seconds=2\\nPrice_History=Price_History_Extract(company_name,stop_seconds)\\nSharePrice_History_Dataframe_to_CSV(Price_History,company_name,Sector)\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To extract one by one\n",
    "'''\n",
    "Sector='Development Banks'\n",
    "company_name='men'\n",
    "stop_seconds=2\n",
    "Price_History=Price_History_Extract(company_name,stop_seconds)\n",
    "SharePrice_History_Dataframe_to_CSV(Price_History,company_name,Sector)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Company underTradingsCategory: 1\n",
      "Now Extracting data of: BBC\n",
      "Number of pages to extract: 24\n",
      "Extracting Heading: \n",
      "Successfully Extracted\n",
      "\n",
      "Currently Extracting in Page:1\n",
      "Rows in current page: 50\n",
      "Columns in current page: 9\n",
      "\n",
      "Successfully Extracted\n",
      "\n",
      "Currently Extracting in Page:2\n",
      "Rows in current page: 50\n",
      "Columns in current page: 9\n",
      "\n",
      "Successfully Extracted\n",
      "\n",
      "Currently Extracting in Page:3\n",
      "Rows in current page: 50\n",
      "Columns in current page: 9\n",
      "\n",
      "Successfully Extracted\n",
      "\n",
      "Currently Extracting in Page:4\n",
      "Rows in current page: 50\n",
      "Columns in current page: 9\n",
      "\n",
      "Successfully Extracted\n",
      "\n",
      "Currently Extracting in Page:5\n",
      "Rows in current page: 50\n",
      "Columns in current page: 9\n",
      "\n",
      "Successfully Extracted\n",
      "\n",
      "Currently Extracting in Page:6\n",
      "Rows in current page: 50\n",
      "Columns in current page: 9\n",
      "\n",
      "Successfully Extracted\n",
      "\n",
      "Currently Extracting in Page:7\n",
      "Rows in current page: 50\n",
      "Columns in current page: 9\n",
      "\n",
      "Successfully Extracted\n",
      "\n",
      "Currently Extracting in Page:8\n",
      "Rows in current page: 50\n",
      "Columns in current page: 9\n",
      "\n",
      "Successfully Extracted\n",
      "\n",
      "Currently Extracting in Page:9\n",
      "Rows in current page: 50\n",
      "Columns in current page: 9\n",
      "\n",
      "Successfully Extracted\n",
      "\n",
      "Currently Extracting in Page:10\n",
      "Rows in current page: 50\n",
      "Columns in current page: 9\n",
      "\n",
      "Successfully Extracted\n",
      "\n",
      "Currently Extracting in Page:11\n",
      "Rows in current page: 50\n",
      "Columns in current page: 9\n",
      "\n",
      "Successfully Extracted\n",
      "\n",
      "Currently Extracting in Page:12\n",
      "Rows in current page: 50\n",
      "Columns in current page: 9\n",
      "\n",
      "Successfully Extracted\n",
      "\n",
      "Currently Extracting in Page:13\n",
      "Rows in current page: 50\n",
      "Columns in current page: 9\n",
      "\n",
      "Successfully Extracted\n",
      "\n",
      "Currently Extracting in Page:14\n",
      "Rows in current page: 50\n",
      "Columns in current page: 9\n",
      "\n",
      "Successfully Extracted\n",
      "\n",
      "Currently Extracting in Page:15\n",
      "Rows in current page: 50\n",
      "Columns in current page: 9\n",
      "\n",
      "Successfully Extracted\n",
      "\n",
      "Currently Extracting in Page:16\n",
      "Rows in current page: 50\n",
      "Columns in current page: 9\n",
      "\n",
      "Successfully Extracted\n",
      "\n",
      "Currently Extracting in Page:17\n",
      "Rows in current page: 50\n",
      "Columns in current page: 9\n",
      "\n",
      "Successfully Extracted\n",
      "\n",
      "Currently Extracting in Page:18\n",
      "Rows in current page: 50\n",
      "Columns in current page: 9\n",
      "\n",
      "Successfully Extracted\n",
      "\n",
      "Currently Extracting in Page:19\n",
      "Rows in current page: 50\n",
      "Columns in current page: 9\n",
      "\n",
      "Successfully Extracted\n",
      "\n",
      "Currently Extracting in Page:20\n",
      "Rows in current page: 50\n",
      "Columns in current page: 9\n",
      "\n",
      "Successfully Extracted\n",
      "\n",
      "Currently Extracting in Page:21\n",
      "Rows in current page: 50\n",
      "Columns in current page: 9\n",
      "\n",
      "Successfully Extracted\n",
      "\n",
      "Currently Extracting in Page:22\n",
      "Rows in current page: 50\n",
      "Columns in current page: 9\n",
      "\n",
      "Successfully Extracted\n",
      "\n",
      "Currently Extracting in Page:23\n",
      "Rows in current page: 50\n",
      "Columns in current page: 9\n",
      "\n",
      "Successfully Extracted\n",
      "\n",
      "Currently Extracting in Page:24\n",
      "Rows in current page: 20\n",
      "Columns in current page: 9\n",
      "\n",
      "Successfully Extracted\n",
      "\n",
      "Shape of Merged PriceHistory Data (1171, 9)\n",
      "\n",
      "Merged PriceHistory Data\n"
     ]
    }
   ],
   "source": [
    "All_company_of_sector_extractor('Tradings',5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
